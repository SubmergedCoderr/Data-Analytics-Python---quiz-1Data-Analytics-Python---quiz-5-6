<h1>ქვიზი სხვადასხვა ტიპის რეგრესიებზე</h1>

<p>
  ეს ქვიზი შედგება ხუთი დავალებისაგან, პირველ დავალებაში ვაკეთებ ერთ ცვლადიანი რეგრესიის მოდელს ყვავილ ზამბახის მონაცემზე, ასეთი ტიპი რეგრესიისათვის ჩვენ გვჭირდება მხოლოდ ორი ცვლადი,
  დამოკიდებული და დამოუკიდებელი,ამიტომაცაა რომ მხოლოდ petal_length და petal_width დავტოვე, petal-width კი არის დამოკიდებული ვლადი ხოლო petal_length დამოუკიდებელი, ამ მოდელში ჩვენ უნდა მოვძებნოთ y= mx +   c - ს training პარამეტრები m da c, რადგან ჩვენი რომელიმე მოცემული x-ისთვის დავაპრედიქტოთ y anu petal_width, დაბლა აგებული პლოტებით კი ვხედავთ რომ ეფექტურად დავატრენინგეთ ჩვენი მონაცემები
</p>

<p>
  მეორე დავალებაში ვაკეთებ მრავალ ცვლადიან რეგრესიის მოდელს insurance.csv - ის გამოყენებით, ვიკვლევ charges მნიშვნელობას დანარჩენი სვეტების ინფორმაციებიდან გამომდინარე, ამიტომაც გარდავქმნი ყველა სვეტის ინფოს ტექსტურიდან რიცხვობრივში, ბოლო რეზულტებში კი ვხედავთ რომ სატესტო მონაცემები ოდნავ უფრო აკურატული იყო ვიდრე დასატრენინგებელი მონცემები, საბოლოო ჯამში მისაღები მოდელია
</p>
 

 <p>
   მესამე დავალებაში ვაკეთებ გადაწყვეტილების ხის რეგრესიის მოდელს, მე ვიყენებ ყველა სვეტის ინფორმაციას, რათა დავაპროგნოზო price-ი, შესაბამისად ჩვენი target ცვლადი იქნება price, აქ ვაწყდებით overfitting პრობლემას, დაიზეპირა ჩვენმა მოდელმა დასატრეინინგებელი მონაცემები, შესაბამისად მოდელი მხოლოდ ამ მონაცემებზე მუშაობს კარგად, ამიტომაც ეს მოდელი ვერ იმუშავებს კარგად სხვა მონაცემებზე, ჩვენ გვინდა რო მოდელმა ნახოს კანონზომიერება და არა დაიზეპიროს ის
</p>

<p>
  მეოთხე დავალებაში ლოგისტიკური რეგრესიის მოდელს ვაგებ, მე ამ დატასეტიდან გამოვიყენებ ყვლეა სვეტის მნშნველობას, რათა დავაპროგნოზო პიროვნებას აქვს თუ არა გულის დააავადება თუ არა, ბოლოს სვეტი AHD არის heart disease , ბოლოს ჩვენი ლოჯისტიკური რეგრესსის score - დან გამომდინარე ვასკვნით რომ ეს რეგრესია აკურატულია
</p>

<p>
  მეხუთე დავალებაში ვაგებ გადაწყვეტილების ხის კლასიფიკაციის მოდელს, ჩემი target ცვლადი იქნება DEATH_EVENT, დანარჩენ ცვლადებს კი გამოვიყენებ მის დასაპროგნოზებლად, რეგრესიის score-დან კი ვხედავთ, რომ დასატრენინგებელ მონაცემებზე 100-პროცენტიანი სიზუსტე გვაქვს, ხოლო სატესტოზე 75 %, ეს კი ჩვენ არ გვინდა, ჩვენ გვინდა რომ ჩვენმა მოდელმა ისევე კარგად იმუშაოს სატესტოზე როგორ დასატრენინგებელზე, ამ მოდელში კი ვხედავთ რომ აშკარად დაზეპირებული აქვს მოდელს და მაგიტომ გვაძლევს ამხელა სიზუსტეს, ამიტომაც ვცადე პარამეტრების ჩაწოდება DecisionTreeClassifier-ისთვის, რამაც სამწუხაროდ კვლავ არასასურველი, თუმცა ოდნავ უკეთესი შედეგი მომცა
</p>
